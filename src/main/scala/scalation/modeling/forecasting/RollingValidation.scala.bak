
//::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** @author  John Miller
 *  @version 2.0
 *  @date    Wed Jun 17 12:08:35 EDT 2020
 *  @see     LICENSE (MIT style license file).
 *
 *  @title   Model Framework: Rolling Validation for Forecasters
 */

package scalation
package modeling
package forecasting

import scalation.mathstat._

import Fit._

//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** Chop the testing te and training tr datasets out of the full dataset
 *  for rolling validation where the training set is before the testing set.
 *  @param x        the full data/input matrix
 *  @param y        the full response/output vector
 *  @param te       the start (inclusive) of the testing region
 *  @param te_size  the size of the testing region
 *  @param tr_size  the size of the training region
 */
def chopr (x: MatrixD, y: VectorD, te: Int, te_size: Int, tr_size: Int):
          (MatrixD, VectorD, MatrixD, VectorD) =
    val DEBUG = false                                               // debug flag
    
    val te2 = te + te_size                                          // end (exclusive) of testing region
    val tr  = te - tr_size                                          // start of training region
    
    val x_e = x(te until te2)                                       // testing data/input matrix
    val y_e = y(te until te2)                                       // testing response/output vector
    val x_  = x(tr until te)                                        // training data/input matrix
    val y_  = y(tr until te)                                        // training response/output vector
    
    if DEBUG then
        println (s"test:  x_e($te .. ${te2 - 1})")
        println (s"test:  y_e($te .. ${te2 - 1})")
        println (s"train: x_($tr .. ${te - 1})")
        println (s"train: y_($tr .. ${te - 1})")
    end if
    
    (x_e, y_e, x_, y_)
end chopr


//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** Chop the testing te and training tr datasets out of the full dataset
 *  for rolling validation where the training set is before the testing set.
 *  This version works for models without an x componenet, only y.
 *  @param y        the full response/output vector
 *  @param te       the start (inclusive) of the testing region
 *  @param te_size  the size of the testing region
 *  @param tr_size  the size of the training region
 */
def chopr (y: VectorD, te: Int, te_size: Int, tr_size: Int):
          (VectorD, VectorD) =
    val DEBUG = false                                               // debug flag

    val te2 = te + te_size                                          // end (exclusive) of testing region
    val tr  = te - tr_size                                          // start of training region

    val y_e = y(te until te2)                                       // testing response/output vector
    val y_  = y(tr until te)                                        // training response/output vector

    if DEBUG then
        println (s"test:  y_e($te .. ${te2 - 1})")
        println (s"train: y_($tr .. ${te - 1})")
    end if

    (y_e, y_)
end chopr


//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** Shift the training dataset right by d2 = xy2._2.dim instances, filling in from
 *  the testing dataset.  Used to update the training dataset before retraining,
 *  e.g., in rolling validation.
 *  @param xy1  the training dataset (matrix, vector)
 *  @param xy2  the portion of the testing dataset to be shifted in (matrix, vector)
 */
def shiftr (xy1: (MatrixD, VectorD), xy2: (MatrixD, VectorD)): (MatrixD, VectorD) =
    val d1  = xy1._2.dim                                             // number of training instances
    val d2  = xy2._2.dim                                             // number of testing instances to shift in
    val gap = d1 - d2                                                // gap from training to be keep
    if xy1._1.dim != d1 then println ("shiftr: dimension mismatch between matrix and vector in xy1")
    if xy2._1.dim != d2 then println ("shiftr: dimension mismatch between matrix and vector in xy2")
    if gap < 1 then println ("shiftr: no gap => nothing needed from training set")

    val x  = new MatrixD (d1, xy1._1.dim2)
    val y  = new VectorD (d1)
    for i <- y.indices do
        if i < gap then
            for j <- x.indices2 do x(i, j) = xy1._1(i+d2, j)
            y(i) = xy1._2(i+d2)
        else
            for j <- x.indices2 do x(i, j) = xy2._1(i-gap, j)
            y(i) = xy2._2(i-gap)
        end if
    end for
    (x, y)
end shiftr


//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** Shift the training dataset right by d2 = y2.dim instances, filling in from
 *  the testing dataset.  Used to update the training dataset before retraining,
 *  e.g., in rolling validation.
 *  This version works for models without an x componenet, only y.
 *  @param y1  the training dataset (vector)
 *  @param y2  the portion of the testing dataset to be shifted in (vector)
 */
def shiftr (y1: VectorD, y2: VectorD): VectorD =
    val d1  = y1.dim                                                 // number of training instances
    val d2  = y2.dim                                                 // number of testing instances to shift in
    val gap = d1 - d2                                                // gap from training to be keep
    if gap < 1 then println ("shiftr: no gap => nothing needed from training set")

    val y  = new VectorD (d1)
    for i <- y.indices do y(i) = if i < gap then y1(i+d2) else y2(i-gap)
    y
end shiftr


//::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `RollingValidation` object provides 1-fold rolling validations, e.g.,
 *  for m = 1200 and k = 1, kt = 5:
 *      1: tr(ain)   0 until  600, te(st)  600 until  1200
 *  In rolling validation for this case, each retraining dataset has 600 instances,
 *  while the testing dataset has 600.  Re-training occurs before every kt = 2
 *  forecasts are made.
 */
object RollingValidation:

    private val debug    = debugf ("RollingValidation", true)                   // debug function
    private val flaw     = flawf ("RollingValidation")                          // debug function
    private val DEBUG2   = false                                                // verbose debug flag
    private val TR_RATIO = 0.5                                                  // min ratio train to full datasets

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Calculate the size (number of instances) for a training dataset.
     *  @param m  the size of the full dataset
     */
    def trSize (m: Int): Int = (m * TR_RATIO).toInt

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Use rolling 1-fold cross-validation to compute test Quality of Fit (QoF) measures
     *  by dividing the dataset into a test dataset and a training dataset.
     *  The test dataset is defined by a range of indices (test start until start + te_size)
     *  and tr_size of the data before this is the training dataset.
     *-------------------------------------------------------------------------
     *  This version is for models that have an x component and y component, e.g., `Regression4TS`.
     *  @see analytics.package.scala for chopr and shiftr methods
     *  @param mod  the forecastering model being used (e.g., `QuadRegression4TS`)
     *  @param kt_  the frequency of re-training (number of forecasts to make before re-training) (defaults to 5)
     *  @param h    the forecasting horizon, number of steps ahead to produce forecasts (defaults to 1)
     */
    def crossValidate (mod: Regression4TS, kt_ : Int = 5, h: Int = 1): Array [Statistic] =
        val x       = mod.getX                                                // get the (opt. expanded) data/input matrix
        val y       = mod.getY                                                // get the (opt. expanded) response/output vector
        val m       = y.dim                                                     // number of instances in full dataset
        val tr_size = trSize (m)                                                // size of each training dataset
        val te_size = m - tr_size                                               // size of each testing dataset
        val kt      = if (kt_ < 0) te_size else kt_                             // given size or size of testing dataset

        debug ("crossValidate", s"m = $m, tr_size = $tr_size, te_size = $te_size, kt = $kt, h = $h")

        if kt < h then flaw ("crossValidate", s"kt = $kt must be at least h = $h")

        val stats   = qofStatTable                                              // table of statistics for QoF measures
        var te      = tr_size                                                   // start of initial testing region

        banner (s"crossValidate: iteration 0: test start te = $te")
        val (x_e, y_e, x_, y_) = chopr (x, y, te, te_size, tr_size)             // chop out testing and training regions

        var xy = (x_, y_)                                                       // initial training dataset (matrix, vector)
        var ym = xy._2.mean                                                     // mean of actual training response
        val yf = new VectorD (y_e.dim)                                          // vector to hold forecasts
        var rt = 0                                                              // re-training counter

        for i <- y_e.indices do                                                 // iterate thru testing instances
            if i % kt == 0 then                                                 // trigger re-training every kt-th iteration
               rt += 1
               if i > 0 then 
                   xy = shiftr (xy, (x_e(i-kt until i), y_e(i-kt until i)))     // update training dataset by shifting
//                 ym = xy._2.mean                                              // update training mean
               end if
               mod.train (xy._1, xy._2)                                         // periodically re-train model on updated training dataset
               if (DEBUG2) println (s"crossValidate: rt = $rt, parameter = ${mod.parameter}")
            end if
//          yf(i) = mod.predict (x_e(i))                                        // save i-th forecasted value for h = 1
            yf(i) = mod.forecast (x_e(i), h)(i, h)                              // save i-th forecasted value - FIX
        end for

// FIX - what should the mean be: ym (from tr) or ym2 (from te)?
//      val ym2 = y_e.mean
//      mod.eval (ym, y_e, yf)                                                  // evaluate model on testing dataset

        val qof = mod.diagnose (y_e, yf)                                        // get Quality of Fit (QoF) measures
        tallyQof (stats, qof)
        debug ("crossValidate", s"number of re-trainings rt = $rt \nqof = " + qof)
        debug ("crossValidate", mod.report (qof) + "\n" + mod.summary)
        new Plot (null, y_e, yf, s"crossValidate (h = $h): ${mod.modelName} fold 0", lines = true)
                                                                                // plot actual test response against forecasted test response
        stats                                                                   // return the statistics table
    end crossValidate

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Use rolling 1-fold cross-validation to compute test Quality of Fit (QoF) measures
     *  by dividing the dataset into a test dataset and a training dataset.
     *  The test dataset is defined by a range of indices (test start until start + te_size)
     *  and tr_size of the data before this is the training dataset.
     *-------------------------------------------------------------------------
     *  This version is for models that have no x component, only the y component, e.g., `AR`.
     *  @see analytics.package.scala for chopr and shiftr methods
     *  @param mod  the forecastering model being used (e.g., `ARIMA`)
     *  @param kt_  the frequency of re-training (number of forecasts to make before re-training) (defaults to 5)
     *  @param h    the forecasting horizon, number of steps ahead to produce forecasts (defaults to 1)
     */
    def crossValidate2 (mod: Forecaster & Fit, kt_ : Int = 5, h: Int = 1): Array [Statistic] =
        val y       = mod.getY                                                // get the (opt. expanded) response/output vector
        val m       = y.dim                                                     // number of instances in full dataset
        val tr_size = trSize (m)                                                // size of each training dataset
        val te_size = m - tr_size                                               // size of each testing dataset
        val kt      = if kt_ < 0 then te_size else kt_                          // given size or size of testing dataset

        debug ("crossValidate2", s"m = $m, tr_size = $tr_size, te_size = $te_size, kt = $kt, h = $h")

        if kt < h then flaw ("crossValidate2", s"kt = $kt must be at least h = $h")

        val stats   = qofStatTable                                              // table of statistics for QoF measures
        var te      = tr_size                                                   // start of initial testing region

        banner (s"crossValidate2: iteration 0: test start te = $te")
        val (y_e, y_) = chopr (y, te, te_size, tr_size)                         // chop out testing and training regions

        var yy = y_                                                             // initial training dataset (vector)
        var ym = yy.mean                                                        // mean of actual training response
        val yf = new VectorD (y_e.dim)                                          // vector to hold forecasts
        var rt = 0                                                              // re-training counter

//      for i <- y_e.indices do                                                 // iterate thru testing instances
        for i <- 0 until yf.dim-h+1 do                                          // iterate thru testing instances
            if i % kt == 0 then                                                 // trigger re-training every kt-th iteration
               rt += 1
               if i > 0 then
                   yy = shiftr (yy, y_e(i-kt until i))                          // update training dataset by shifting
//                 ym = yy.mean                                                 // update training mean
               end if
               mod.train (null, yy)                                             // periodically re-train model on updated training dataset
               if (DEBUG2) println (s"crossValidate2: rt = $rt, parameter = ${mod.parameter}")
            end if
            // use time t = tr_size + i to adjust the index with respect to the original y
            yf(i+h-1) = mod.forecastX (y, tr_size + i, h)  // , i % kt)       // save i-th forecasted value
        end for

        for i <- 0 until h-1 do yf(i) = y_e(i)        // when h > 1, fill in initial blanks in yf with actual y values

// FIX - what should the mean be: ym (from tr) or ym2 (from te)?
//      val ym2 = y_e.mean
//      mod.eval (ym, y_e, yf)                                                // evaluate model on testing dataset
//      val e = y_e - yf                              // must create local e since the original e may be required for MA models
//      mod.diagnose (e, y_e, yf)
//      mod.evalf (y_e, yf)

        val qof = mod.diagnose (y_e, yf)                                        // get Quality of Fit (QoF) measures
        tallyQof (stats, qof)
        debug ("crossValidate2", s"number of re-trainings rt = $rt \nqof = " + qof)
        debug ("crossValidate2", mod.report (qof))
        new Plot (null, y_e, yf, s"crossValidate2 (h = $h): ${mod.modelName} fold 0", lines = true)
                                                                                // plot actual test response against forecasted test response
        stats                                                                   // return the statistics table
    end crossValidate2

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Use rolling 1-fold cross-validation to compute test Quality of Fit (QoF) measures
     *  by dividing the dataset into a test dataset and a training dataset.
     *  The test dataset is defined by a range of indices (test start until start + te_size)
     *  and tr_size of the data before this is the training dataset.
     *-------------------------------------------------------------------------
     *  This version is for models that have no x component, only the y component, e.g., `AR`.
     *  @see analytics.package.scala for chopr and shiftr methods
     *  @param mod  the forecastering model being used (e.g., `ARIMA`)
     *  @param kt_  the frequency of re-training (number of forecasts to make before re-training) (defaults to 5)
     *  @param h    the forecasting horizon, number of steps ahead to produce forecasts (defaults to 1)
     *
    def crossValidate2S (mod: SARIMA, kt_ : Int = 5, h: Int = 1): Array [Statistic] =
        val y       = mod.getY                                                // get the (opt. expanded) response/output vector
        val m       = y.dim                                                     // number of instances in full dataset
        val tr_size = trSize (m)                                                // size of each training dataset
        val te_size = m - tr_size                                               // size of each testing dataset
        val kt      = if kt_ < 0 then te_size else kt_                             // given size or size of testing dataset

        debug ("crossValidate2S", s"m = $m, tr_size = $tr_size, te_size = $te_size, kt = $kt, h = $h")

        if kt < h then flaw ("crossValidate2S", s"kt = $kt must be at least h = $h")

        val stats   = qofStatTable                                              // table of statistics for QoF measures
        val te      = tr_size                                                   // start of initial testing region

        banner (s"crossValidate2S: iteration 0: test start te = $te")
        val (y_e, y_) = chopr (y, te, te_size, tr_size)                         // chop out testing and training regions

        var yy = y_                                                             // initial training dataset (vector)
        var ym = yy.mean                                                        // mean of actual training response
        val yf = new VectorD (y_e.dim)                                          // vector to hold forecasts
        var rt = 0                                                              // re-training counter

//      for i <- y_e.indices do                                                 // iterate thru testing instances
        for i <- 0 until yf.dim-h+1 do                                          // iterate thru testing instances
            yy = y(i until i+tr_size)
            mod.setTS (yy)

            if i % kt == 0 then                                                 // trigger re-training every kt-th iteration
               rt += 1
               mod.train ()                                           // periodically re-train model on updated training dataset
               if (DEBUG2) println (s"crossValidate2: rt = $rt") //, parameter = ${mod.parameter}")
            else mod.updateFittedValues()                              // update the fitted values without retraining


            // use time t = tr_size + i to adjust the index with respect to the original y
            yf(i+h-1) = mod.forecast (yy.dim, h).last             // save i-th forecasted value
        end for

        for i <- 0 until h-1 do yf(i) = y_e(i)        // when h > 1, fill in initial blanks in yf with actual y values

// FIX - what should the mean be: ym (from tr) or ym2 (from te)?
//      val ym2 = y_e.mean
//      mod.eval (ym, y_e, yf)                                                // evaluate model on testing dataset
//      val e = y_e - yf                              // must create local e since the original e may be required for MA models
//      mod.diagnose (e, y_e, yf)
//      mod.eval (y_e, yf)

        val (yp, qof) = mod.test (y_e, yf)                                      // get Quality of Fit (QoF) measures
        tallyQof (stats, qof)
        debug ("crossValidate2S", s"number of re-trainings rt = $rt \nqof = " + qof)
        debug (crossValidate2S", mod.fitMap)
        new Plot (null, y_e, yf, s"crossValidate2S (h = $h): ${mod.modelName} fold 0", lines = true)
                                                                                // plot actual test response against forecasted test response
        stats                                                                   // return the statistics table
    end crossValidate2S
     */

    //:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
    /** Use rolling 1-fold cross-validation to compute test Quality of Fit (QoF) measures
     *  by dividing the dataset into a test dataset and a training dataset.
     *  The test dataset is defined by a range of indices (test start until start + te_size)
     *  and tr_size of the data before this is the training dataset.
     *-------------------------------------------------------------------------
     *  This version is for models that have an x component and y component, e.g., `NeuralNet_3L1_4TS`.
     *  @see analytics.package.scala for chopr and shiftr methods
     *  @param mod  the forecastering model being used (e.g., `NeuralNet_3L1_4TS`)
     *  @param kt_  the frequency of re-training (number of forecasts to make before re-training) (defaults to 50)
     *  @param h    the forecasting horizon, number of steps ahead to produce forecasts (defaults to 1)
     *
    def crossValidate3 (mod: Forecaster, kt_ : Int = 50, h: Int = 1): Array [Statistic] =
        val x       = mod.getX                                                // get the (opt. expanded) data/input matrix
        val y       = mod.getY                                                // get the (opt. expanded) response/output vector
        val m       = y.dim                                                     // number of instances in full dataset
        val tr_size = trSize (m)                                                // size of each training dataset
        val te_size = m - tr_size                                               // size of each testing dataset
        val kt      = if (kt_ < 0) te_size else kt_                             // given size or size of testing dataset

        debug("crossValidate3", s"m = $m, tr_size = $tr_size, te_size = $te_size, kt = $kt, h = $h")

        if kt < h then flaw ("crossValidate3", s"kt = $kt must be at least h = $h")

        val stats   = qofStatTable                                              // table of statistics for QoF measures
        var te      = tr_size                                                   // start of initial testing region

        banner (s"crossValidate3: iteration 0: test start te = $te")
        val (x_e, y_e, x_, y_) = chopr (x, y, te, te_size, tr_size)             // chop out testing and training regions

        var xy = (x_, y_)                                                       // initial training dataset (matrix, vector)
        var ym = xy._2.mean                                                     // mean of actual training response
        val yf = new VectorD (y_e.dim)                                          // vector to hold forecasts
        var rt = 0                                                              // re-training counter

        for i <- y_e.indices do                                                  // iterate thru testing instances
            if i % kt == 0 then                                                  // trigger re-training every kt-th iteration
               rt += 1
               if i > 0 then
                   xy = shiftr (xy, (x_e(i-kt until i), y_e(i-kt until i)))   // update training dataset by shifting
//                 ym = xy._2.mean                                                 // update training mean
               end if
               mod.train (xy._1, xy._2)                                       // periodically re-train model on updated training dataset
               if DEBUG2 then println (s"crossValidate3: rt = $rt, parameter = ${mod.parameter}")
            end if
//          yf(i) = mod.predict (x_e(i))                                      // save i-th forecasted value for h = 1
            yf(i) = mod.forecast (x_e, i, h)                                  // save i-th forecasted value
        end for

// FIX - what should the mean be: ym (from tr) or ym2 (from te)?
//      val ym2 = y_e.mean
        mod.eval (ym, y_e, yf)                                                // evaluate model on testing dataset

        val qof = mod.fitA(0).fit                                             // get Quality of Fit (QoF) measures
        tallyQof (stats, qof)
        debug ("crossValidate3", s"number of re-trainings rt = $rt \nqof = " + qof)
//      debug ("crossValidate3", mod.report (qof) + "\n" + mod.summary)
        new Plot (null, y_e, yf, s"crossValidate3 (h = $h): ${mod.modelName} fold 0", lines = true)
                                                                                // plot actual test response against forecasted test response
        stats                                                                   // return the statistics table
    end crossValidate3
     */

end RollingValidation


//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `rollingValidationTest` object is used to test the crossValidate method
 *  in the `RollingValidation` object.
 *  > runMain scalation.analytics.forecaster.rollingValidationTest
 */
@main def rollingValidationTest (): Unit =

    import scalation.random.Normal

    val m = 1200                                                                // number of instances
    val x = new MatrixD (m, 2)                                                  // data/input matrix
    val y = new VectorD (m)                                                     // response/output vector
    val e = Normal (0, 20000000)                                                // noise

    for i <- y.indices do
        val j = i + 1
        x(i, 0) = 0.0000001 * (j - m/2)~^3 * - 5 * j
        x(i, 1) = 10 * j -  0.0001 * j~^2 
        y(i) = 10.0 + 3 * x(i, 0) + 2 * x(i, 1) + e.gen
    end for

    val h = 1                                                                   // forecasting horizon, try changing
    banner (s"Regression4TS full dataset results at forecasting horizon h = $h")
    val mod = new Regression4TS (x, y, 3)
    mod.train (null, y)                                                         // train the model on full dataset
    val (yp, qof) = mod.test (null, y)                                          // test the model on full dataset
    println (mod.report (qof))                                                  // report on Quality of Fit (QoF)

    banner (s"Regression4TS rolling validation results at forecasting horizon h = $h")
    FitM.showQofStatTable (RollingValidation.crossValidate (mod, h = h))

end rollingValidationTest


//:::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::::
/** The `rollingValidationTest2` object is used to test the crossValidate2 method
 *  in the `RollingValidation` object.
 *  > runMain scalation.analytics.forecaster.rollingValidationTest2
 */
@main def rollingValidationTest2 (): Unit =

    import scalation.random.Normal

    val m = 1200                                                                // number of instances
    val y = new VectorD (m)                                                     // response/output vector
    val e = Normal (0, 100)                                                     // noise

    y(0) = 50.0
    for i <- 1 until y.dim do y(i) = 0.8 * y(i-1) + e.gen

    println (s"y.min = ${y.min}, y.max = ${y.max}")

    val h = 2                                                                   // forecasting horizon, try changing
    banner (s"AR full dataset results at forecasting horizon h = $h")
    ARMA.hp("p") = 2
    val mod = new AR (y)                                                        // create an AR(p) model
    mod.train (null, y)                                                         // train the model on full dataset
    val (yp, qof) = mod.test (null, y)                                          // test the model on full dataset
    println (mod.report (qof))                                                  // report on Quality of Fit (QoF)

    banner (s"AR rolling validation validation results at forecasting horizon h = $h")
    FitM.showQofStatTable (RollingValidation.crossValidate2 (mod, h = h))

end rollingValidationTest2

